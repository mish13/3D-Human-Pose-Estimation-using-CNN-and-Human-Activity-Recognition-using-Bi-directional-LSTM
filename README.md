# 3D-Human-Pose-Estimation-using-CNN-and-Human-Activity-Recognition-using-Bi-directional-LSTM
We propose a strategy to detect 3D pose for multiple people from any image and real-time video stream and recognize the activity of the person(s) based on sequential information from it.  Firstly, Convolutional Neural Network is used to find the features as the key points and Part Affinity Fields to associate human body parts with the respective person's body and creates a stick figure for that person. This exploits greedy bottom-up parsing to maintain high accuracy irrespective of the number of persons in a frame. COCO Human Keypoint Challenge dataset has been used to train the system to find the posture and stick-figure from image or video. The second phase is proposed to use the sequence-based architecture of Bidirectional Long Short-Term Memory to predict the activity of the person. These activities are categorized into some classes like, walking, walking upstairs, walking downstairs, sitting, standing and laying. The activity is detected from the stick figure's movement from the video stream which is the yield of the first phase. But because of the unavailability of the necessary dataset of key points for human activity recognition from any video stream, a dataset from smartphone accelerometer is used to predict the activities using Bidirectional Long Short-Term Memory.
